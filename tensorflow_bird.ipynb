{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noon/src/python/tensorflow/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#メソッドまとめ\n",
    "#  1.  augument_image(output_dirs, orig_dirs)\n",
    "#  2.  resize_images(target_dirs, base_dirs, data_names, data_nums, new_size)\n",
    "#  3.  make_data(dataset_index)\n",
    "#  4.  generate_test_train_data(data, label, test_size)\n",
    "#  5.  save_test_train_data(data, label, test_size, dataset_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augument_image(output_dirs, orig_dirs):\n",
    "    #引数\n",
    "    # ouput_dir: 出力先のパス\n",
    "    # orig_dir: 元データのパス\n",
    "    \n",
    "    for output_dir, orig_dir in zip(output_dirs, orig_dirs):\n",
    "        if not(os.path.exists(output_dir)):\n",
    "            os.mkdir(output_dir)\n",
    "\n",
    "        # 拡張する画像群の読み込み\n",
    "        images = glob.glob(os.path.join(orig_dir+'/', \"*.jpeg\"))\n",
    "\n",
    "        # 拡張する際の設定\n",
    "        generator = ImageDataGenerator(\n",
    "                        rotation_range=90, # 90°まで回転\n",
    "                        width_shift_range=0.1, # 水平方向にランダムでシフト\n",
    "                        height_shift_range=0.1, # 垂直方向にランダムでシフト\n",
    "                        channel_shift_range=0.0, # 色調をランダム変更\n",
    "                        shear_range=0.39, # 斜め方向(pi/8まで)に引っ張る\n",
    "                        horizontal_flip=True, # 垂直方向にランダムで反転\n",
    "                        vertical_flip=True # 水平方向にランダムで反転\n",
    "                        )\n",
    "\n",
    "        # 読み込んだ画像を順に拡張\n",
    "        for i in range(len(images)):\n",
    "            img = load_img(images[i])\n",
    "            # 画像を配列化して転置a\n",
    "            x = img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            # 画像の拡張\n",
    "            draw_images(generator, x, output_dir, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の枚数\n",
    "# mukudori: 1139\n",
    "# suzume: 970\n",
    "\n",
    "def resize_images(target_dirs, base_dirs, data_names, data_nums, new_size):\n",
    "    #引数\n",
    "    # target_dirs: 出力先のパス\n",
    "    # base_dirs: 元データのパス\n",
    "    # data_nums: 元データのデータ枚数\n",
    "    # new_size:　リサイズ先の一辺の長さ(もともとは28x28だった)\n",
    "    \n",
    "    for target_dir, base_dir, data_name, data_num in zip(target_dirs, base_dirs, data_names, data_nums):\n",
    "        for i in range(data_num):\n",
    "            index = str(i)\n",
    "            image = Image.open(base_dir+dir_name+\"/\"+dir_name+\"_\"+index+\".jpeg\")\n",
    "            image = image.resize((new_size,new_size))\n",
    "\n",
    "            if(os.path.isfile(target_dir+dir_name+\"/\"+dir_name+\"_\"+index+\".jpeg\")):\n",
    "                os.remove(target_dir+dir_name+\"/\"+dir_name+\"_\"+index+\".jpeg\")\n",
    "            image.save(target_dir+dir_name+\"/\"+dir_name+\"_\"+index+\".jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(dataset_index):\n",
    "    data_names = [\"mukudori\", \"suzume\"]\n",
    "    data_nums = [1139, 968] #[m_num, s_num]\n",
    "    datas = [[], []] #[m_label, s_label]\n",
    "    labels = [[], []]\n",
    "    data_dirs = ['./dataset_'+dataset_index+'/resized/mukudori/', './dataset_'+dataset_index+'/resized/suzume/'] #m_dir, s_dir\n",
    "\n",
    "    for data_num, data, label, data_dir, data_name in zip(data_nums, datas, labels, data_dirs, data_names):\n",
    "        for i in range(data_num):\n",
    "            data.append(0)\n",
    "            if data_name == 'mukudori':\n",
    "                label.append([1, 0])\n",
    "            else:\n",
    "                label.append([0, 1])\n",
    "        \n",
    "        for i in range(data_num):\n",
    "            index = str(i)\n",
    "            data[i] = Image.open(data_dir+data_name+'_'+index+'.jpeg')\n",
    "            width, height = data[i].size\n",
    "            \n",
    "            img_pixels = []\n",
    "            for y in range(height):\n",
    "                for x in range(width):\n",
    "                    img_pixels.append(data[i].getpixel((x, y)))\n",
    "\n",
    "            data[i] = np.array(img_pixels)\n",
    "            data[i] = np.reshape(data[i], (28, 28, 3))\n",
    "    \n",
    "    concat_data = datas[0] + datas[1]\n",
    "    concat_label = labels[0] + labels[1]\n",
    "    \n",
    "    return concat_data, concat_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_train_data(data, label, test_size):\n",
    "    return  train_test_split(data, label, test_size=0.3)\n",
    "    # Data_train, Data_test, Label_train, Label_test の形式で帰ってくる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test_train_data(data, label, test_size, dataset_index=-1):\n",
    "    D_train, D_test, L_train, L_test = generate_test_train_data()\n",
    "    \n",
    "    if not data_set_index == -1:\n",
    "        index = str(dataset_index)\n",
    "        np.save('./dataset_'+index+'/data/D_train', D_train)\n",
    "        np.save('./dataset_'+index+'/data/D_test', D_test)\n",
    "        np.save('./dataset_'+index+'/data/L_train', L_train)\n",
    "        np.save('./dataset_'+index+'/data/L_test', L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE * 3\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "# flags.DEFINE_string('image_dir', 'dataset_1/resized', 'Directory of images')\n",
    "# flags.DEFINE_string('train_dir', 'logs', 'Directory to put the training data.')\n",
    "# flags.DEFINE_integer('max_steps', 200, 'Number of steps to run trainer.')\n",
    "# flags.DEFINE_integer('batch_size', 10, 'Batch size'\n",
    "#                      'Must divide evenly into the dataset sizes.')\n",
    "# flags.DEFINE_float('learning_rate', 1e-5, 'Initial learning rate.')\n",
    "image_dir = 'dataset_2/images'\n",
    "train_dir = 'dataset_2/logs'\n",
    "max_steps = 200\n",
    "batch_size = 10\n",
    "learning_rate = 1e-5\n",
    "\n",
    "def inference(images_placeholder, keep_prob):\n",
    "    #重みをstd=0.1で初期化\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    #バイアスをstd=0.1で初期化\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    #畳み込み層の作成\n",
    "    def conv2d(x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "    \n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    x_image = tf.reshape(images_placeholder, [-1, 28, 28, 3])\n",
    "    \n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        W_conv1 = weight_variable([5, 5, 3, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1)+b_conv1)\n",
    "        tf.summary.histogram(\"wc1\", W_conv1)\n",
    "    \n",
    "    with tf.name_scope('pool1') as scope:\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "    \n",
    "    with tf.name_scope('conv2') as scope:\n",
    "        W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        tf.summary.histogram(\"wc2\", W_conv2)\n",
    "    \n",
    "    with tf.name_scope('pool2') as scope:\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "    \n",
    "    with tf.name_scope('fc1') as scope:\n",
    "        W_fc1 = weight_variable([7*7*64, 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    \n",
    "    with tf.name_scope('fc2') as scope:\n",
    "        W_fc2 = weight_variable([1024, NUM_CLASSES])\n",
    "        b_fc2 = bias_variable([NUM_CLASSES])\n",
    "    \n",
    "    with tf.name_scope('softmax') as scope:\n",
    "        y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "    \n",
    "    return y_conv\n",
    "\n",
    "def loss(logits, labels):\n",
    "    #交差エントロピーの計算\n",
    "    cross_entropy = -tf.reduce_sum(labels*tf.log(logits))\n",
    "    #tensorboard用\n",
    "    tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
    "    return cross_entropy\n",
    "\n",
    "def training(loss, learning_rate):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return train_step\n",
    "\n",
    "def accuracy(logits, labels):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, label = make_data(str(1))\n",
    "# train_image, test_image, train_label, test_label = generate_test_train_data(data, label, test_size=0.3)\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for i in range(10):\n",
    "    train_image = []\n",
    "    train_label = []\n",
    "    with open('dataset_2/train'+str(i)+'.txt') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            l = line.split()\n",
    "            img = cv2.imread(image_dir+'/'+l[0])\n",
    "#             print(l[0])\n",
    "            img = cv2.resize(img, (28, 28))\n",
    "\n",
    "            train_image.append(img.flatten().astype(np.float32)/255.0)\n",
    "            tmp = np.zeros(NUM_CLASSES)\n",
    "            tmp[int(l[1])] = 1\n",
    "            train_label.append(tmp)\n",
    "        train_images.append(np.asarray(train_image))\n",
    "        train_labels.append(np.asarray(train_label))\n",
    "\n",
    "    test_image = []\n",
    "    test_label = []\n",
    "    with open('dataset_2/test'+str(i)+'.txt') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            l = line.split()\n",
    "            img = cv2.imread(image_dir+'/'+l[0])\n",
    "            img = cv2.resize(img, (28, 28))\n",
    "\n",
    "            test_image.append(img.flatten().astype(np.float32)/255.0)\n",
    "            tmp = np.zeros(NUM_CLASSES)\n",
    "            tmp[int(l[1])] = 1\n",
    "            test_label.append(tmp)\n",
    "        test_images.append(np.asarray(test_image))\n",
    "        test_labels.append(np.asarray(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = '2'\n",
    "np.save('./dataset_'+index+'/data/train_images', train_images)\n",
    "np.save('./dataset_'+index+'/data/train_labels', train_labels)\n",
    "np.save('./dataset_'+index+'/data/test_images', test_images)\n",
    "np.save('./dataset_'+index+'/data/test_labels', test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.539641\n",
      "step 1, training accuracy 0.539641\n",
      "step 2, training accuracy 0.539641\n",
      "step 3, training accuracy 0.539641\n",
      "step 4, training accuracy 0.540698\n",
      "step 5, training accuracy 0.544926\n",
      "step 6, training accuracy 0.553383\n",
      "step 7, training accuracy 0.557611\n",
      "step 8, training accuracy 0.564482\n",
      "step 9, training accuracy 0.570825\n",
      "step 10, training accuracy 0.578224\n",
      "step 11, training accuracy 0.59408\n",
      "step 12, training accuracy 0.600423\n",
      "step 13, training accuracy 0.613636\n",
      "step 14, training accuracy 0.61945\n",
      "step 15, training accuracy 0.622622\n",
      "step 16, training accuracy 0.642706\n",
      "step 17, training accuracy 0.642178\n",
      "step 18, training accuracy 0.656448\n",
      "step 19, training accuracy 0.656977\n",
      "step 20, training accuracy 0.661734\n",
      "step 21, training accuracy 0.661205\n",
      "step 22, training accuracy 0.678118\n",
      "step 23, training accuracy 0.683404\n",
      "step 24, training accuracy 0.67389\n",
      "step 25, training accuracy 0.705603\n",
      "step 26, training accuracy 0.682347\n",
      "step 27, training accuracy 0.697674\n",
      "step 28, training accuracy 0.715645\n",
      "step 29, training accuracy 0.716173\n",
      "step 30, training accuracy 0.717759\n",
      "step 31, training accuracy 0.725687\n",
      "step 32, training accuracy 0.723044\n",
      "step 33, training accuracy 0.730973\n",
      "step 34, training accuracy 0.739429\n",
      "step 35, training accuracy 0.739429\n",
      "step 36, training accuracy 0.752114\n",
      "step 37, training accuracy 0.743658\n",
      "step 38, training accuracy 0.747357\n",
      "step 39, training accuracy 0.765328\n",
      "step 40, training accuracy 0.770085\n",
      "step 41, training accuracy 0.773784\n",
      "step 42, training accuracy 0.761099\n",
      "step 43, training accuracy 0.765328\n",
      "step 44, training accuracy 0.782241\n",
      "step 45, training accuracy 0.783827\n",
      "step 46, training accuracy 0.778541\n",
      "step 47, training accuracy 0.789112\n",
      "step 48, training accuracy 0.794397\n",
      "step 49, training accuracy 0.803911\n",
      "step 50, training accuracy 0.804968\n",
      "step 51, training accuracy 0.814482\n",
      "step 52, training accuracy 0.816596\n",
      "step 53, training accuracy 0.824524\n",
      "step 54, training accuracy 0.80814\n",
      "step 55, training accuracy 0.835095\n",
      "step 56, training accuracy 0.836681\n",
      "step 57, training accuracy 0.829281\n",
      "step 58, training accuracy 0.840909\n",
      "step 59, training accuracy 0.845666\n",
      "step 60, training accuracy 0.854123\n",
      "step 61, training accuracy 0.853594\n",
      "step 62, training accuracy 0.85148\n",
      "step 63, training accuracy 0.864165\n",
      "step 64, training accuracy 0.860994\n",
      "step 65, training accuracy 0.865751\n",
      "step 66, training accuracy 0.849366\n",
      "step 67, training accuracy 0.868393\n",
      "step 68, training accuracy 0.867865\n",
      "step 69, training accuracy 0.867336\n",
      "step 70, training accuracy 0.868922\n",
      "step 71, training accuracy 0.886892\n",
      "step 72, training accuracy 0.882135\n",
      "step 73, training accuracy 0.883721\n",
      "step 74, training accuracy 0.878964\n",
      "step 75, training accuracy 0.889006\n",
      "step 76, training accuracy 0.895349\n",
      "step 77, training accuracy 0.888478\n",
      "step 78, training accuracy 0.899577\n",
      "step 79, training accuracy 0.890592\n",
      "step 80, training accuracy 0.901163\n",
      "step 81, training accuracy 0.903277\n",
      "step 82, training accuracy 0.907505\n",
      "step 83, training accuracy 0.913848\n",
      "step 84, training accuracy 0.921247\n",
      "step 85, training accuracy 0.912791\n",
      "step 86, training accuracy 0.919662\n",
      "step 87, training accuracy 0.918605\n",
      "step 88, training accuracy 0.917548\n",
      "step 89, training accuracy 0.924419\n",
      "step 90, training accuracy 0.913319\n",
      "step 91, training accuracy 0.926533\n",
      "step 92, training accuracy 0.934461\n",
      "step 93, training accuracy 0.933404\n",
      "step 94, training accuracy 0.927061\n",
      "step 95, training accuracy 0.943446\n",
      "step 96, training accuracy 0.939746\n",
      "step 97, training accuracy 0.940275\n",
      "step 98, training accuracy 0.934989\n",
      "step 99, training accuracy 0.938161\n",
      "step 100, training accuracy 0.951374\n",
      "step 101, training accuracy 0.95296\n",
      "step 102, training accuracy 0.959831\n",
      "step 103, training accuracy 0.95666\n",
      "step 104, training accuracy 0.962474\n",
      "step 105, training accuracy 0.959302\n",
      "step 106, training accuracy 0.963531\n",
      "step 107, training accuracy 0.966702\n",
      "step 108, training accuracy 0.972516\n",
      "step 109, training accuracy 0.968816\n",
      "step 110, training accuracy 0.963531\n",
      "step 111, training accuracy 0.963002\n",
      "step 112, training accuracy 0.969345\n",
      "step 113, training accuracy 0.973573\n",
      "step 114, training accuracy 0.975159\n",
      "step 115, training accuracy 0.977273\n",
      "step 116, training accuracy 0.972516\n",
      "step 117, training accuracy 0.985729\n",
      "step 118, training accuracy 0.98203\n",
      "step 119, training accuracy 0.984144\n",
      "step 120, training accuracy 0.984144\n",
      "step 121, training accuracy 0.984144\n",
      "step 122, training accuracy 0.986786\n",
      "step 123, training accuracy 0.987315\n",
      "step 124, training accuracy 0.991015\n",
      "step 125, training accuracy 0.983615\n",
      "step 126, training accuracy 0.990486\n",
      "step 127, training accuracy 0.983087\n",
      "step 128, training accuracy 0.987844\n",
      "step 129, training accuracy 0.989958\n",
      "step 130, training accuracy 0.989429\n",
      "step 131, training accuracy 0.991543\n",
      "step 132, training accuracy 0.993658\n",
      "step 133, training accuracy 0.990486\n",
      "step 134, training accuracy 0.993129\n",
      "step 135, training accuracy 0.9963\n",
      "step 136, training accuracy 0.995772\n",
      "step 137, training accuracy 0.998943\n",
      "step 138, training accuracy 0.995772\n",
      "step 139, training accuracy 0.995772\n",
      "step 140, training accuracy 0.995243\n",
      "step 141, training accuracy 0.998414\n",
      "step 142, training accuracy 0.9963\n",
      "step 143, training accuracy 0.994715\n",
      "step 144, training accuracy 0.993129\n",
      "step 145, training accuracy 0.994715\n",
      "step 146, training accuracy 0.995772\n",
      "step 147, training accuracy 0.998414\n",
      "step 148, training accuracy 0.9963\n",
      "step 149, training accuracy 0.995243\n",
      "step 150, training accuracy 0.998414\n",
      "step 151, training accuracy 0.998943\n",
      "step 152, training accuracy 0.999471\n",
      "step 153, training accuracy 0.997357\n",
      "step 154, training accuracy 1\n",
      "step 155, training accuracy 1\n",
      "step 156, training accuracy 0.998943\n",
      "step 157, training accuracy 0.999471\n",
      "step 158, training accuracy 0.999471\n",
      "step 159, training accuracy 0.999471\n",
      "step 160, training accuracy 1\n",
      "step 161, training accuracy 1\n",
      "step 162, training accuracy 0.999471\n",
      "step 163, training accuracy 0.999471\n",
      "step 164, training accuracy 0.999471\n",
      "step 165, training accuracy 1\n",
      "step 166, training accuracy 1\n",
      "step 167, training accuracy 0.999471\n",
      "step 168, training accuracy 0.998414\n",
      "step 169, training accuracy 1\n",
      "step 170, training accuracy 1\n",
      "step 171, training accuracy 1\n",
      "step 172, training accuracy 1\n",
      "step 173, training accuracy 1\n",
      "step 174, training accuracy 1\n",
      "step 175, training accuracy 1\n",
      "step 176, training accuracy 1\n",
      "step 177, training accuracy 1\n",
      "step 178, training accuracy 1\n",
      "step 179, training accuracy 1\n",
      "step 180, training accuracy 1\n",
      "step 181, training accuracy 1\n",
      "step 182, training accuracy 1\n",
      "step 183, training accuracy 1\n",
      "step 184, training accuracy 1\n",
      "step 185, training accuracy 1\n",
      "step 186, training accuracy 1\n",
      "step 187, training accuracy 1\n",
      "step 188, training accuracy 1\n",
      "step 189, training accuracy 1\n",
      "step 190, training accuracy 1\n",
      "step 191, training accuracy 1\n",
      "step 192, training accuracy 1\n",
      "step 193, training accuracy 1\n",
      "step 194, training accuracy 1\n",
      "step 195, training accuracy 1\n",
      "step 196, training accuracy 1\n",
      "step 197, training accuracy 1\n",
      "step 198, training accuracy 1\n",
      "step 199, training accuracy 1\n",
      "test accuracy 0.876777\n",
      "step 0, training accuracy 0.539641\n",
      "step 1, training accuracy 0.539641\n",
      "step 2, training accuracy 0.539641\n",
      "step 3, training accuracy 0.540169\n",
      "step 4, training accuracy 0.540169\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-539e76eedd31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mimages_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mlabels_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 })\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noon/src/python/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noon/src/python/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noon/src/python/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noon/src/python/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noon/src/python/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noon/src/python/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for train_image, train_label, test_image, test_label in zip(train_images, train_labels, test_images, test_labels):\n",
    "    with tf.Graph().as_default():\n",
    "        images_placeholder = tf.placeholder(\"float\", shape=(None, IMAGE_PIXELS))\n",
    "        labels_placeholder = tf.placeholder(\"float\", shape=(None, NUM_CLASSES))\n",
    "\n",
    "        #dropout率\n",
    "        keep_prob = tf.placeholder(\"float\")\n",
    "        #モデル\n",
    "        logits = inference(images_placeholder, keep_prob)\n",
    "        #損失計算\n",
    "        loss_value = loss(logits, labels_placeholder)\n",
    "        #学習\n",
    "        train_op = training(loss_value, learning_rate)\n",
    "        #精度計算\n",
    "        acc = accuracy(logits, labels_placeholder)\n",
    "        #保存準備\n",
    "        saver = tf.train.Saver()\n",
    "        #セッションの作成\n",
    "        sess = tf.Session()\n",
    "        #変数の初期化\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        #Tensorboard表示用の設定\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        summary_writer = tf.summary.FileWriter(train_dir, sess.graph)\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            for i in range(int(len(train_image)/batch_size)):\n",
    "                batch = batch_size * i\n",
    "                sess.run(train_op, feed_dict={\n",
    "                    images_placeholder: train_image[batch: batch+batch_size],\n",
    "                    labels_placeholder: train_label[batch: batch+batch_size],\n",
    "                    keep_prob: 0.5\n",
    "                })\n",
    "\n",
    "            train_accuracy = sess.run(acc, feed_dict={\n",
    "                images_placeholder: train_image,\n",
    "                labels_placeholder: train_label,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "            print(\"step %d, training accuracy %g\"%(step, train_accuracy))\n",
    "\n",
    "            summary_str = sess.run(summary_op, feed_dict={\n",
    "                images_placeholder: train_image,\n",
    "                labels_placeholder: train_label,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "            summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "    print(\"test accuracy %g\"%sess.run(acc, feed_dict={\n",
    "        images_placeholder: test_image,\n",
    "        labels_placeholder: test_label,\n",
    "        keep_prob: 1.0\n",
    "    }))\n",
    "\n",
    "    save_path = saver.save(sess, os.getcwd() + \"¥¥model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.784689\n"
     ]
    }
   ],
   "source": [
    "    print(\"test accuracy %g\"%sess.run(acc, feed_dict={\n",
    "        images_placeholder: test_images[9],\n",
    "        labels_placeholder: test_labels[9],\n",
    "        keep_prob: 1.0\n",
    "    }))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
